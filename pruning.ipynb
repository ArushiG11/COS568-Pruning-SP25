{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArushiG11/COS568-Pruning-SP25/blob/main/pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgOfiXbvUso",
        "outputId": "0bf444bd-7d95-4a85-ba81-905d0468b86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COS568-Pruning-SP25'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 112 (delta 49), reused 104 (delta 46), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (112/112), 1.36 MiB | 3.27 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tzadouri/COS568-Pruning-SP25.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7v_LyvkYv0Zi",
        "outputId": "1c48c94a-8880-45c8-ba22-ae75b4527b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r COS568-Pruning-SP25/requirements.txt (line 1)) (4.67.1)\n",
            "Collecting argparse (from -r COS568-Pruning-SP25/requirements.txt (line 2))\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: matplotlib>2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r COS568-Pruning-SP25/requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r COS568-Pruning-SP25/requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r COS568-Pruning-SP25/requirements.txt (line 5)) (2.2.2)\n",
            "Collecting torch==2.6.0 (from -r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0 (from -r COS568-Pruning-SP25/requirements.txt (line 7))\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6))\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0->-r COS568-Pruning-SP25/requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r COS568-Pruning-SP25/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r COS568-Pruning-SP25/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>2.0.0->-r COS568-Pruning-SP25/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->-r COS568-Pruning-SP25/requirements.txt (line 6)) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, argparse, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argparse-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "06999de3ae99459081b23a065b14ad60",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r COS568-Pruning-SP25/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBtyJoHr4cDt",
        "outputId": "6366a4a8-ae60-4227-f38b-b5e109398335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is available\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFEPlw-rOFX3"
      },
      "source": [
        "**VGG16 Model with CIFAR-10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip9cO5nGKQCg",
        "outputId": "1343420f-6533-4e00-ddba-dded8c284756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "100% 170M/170M [00:03<00:00, 47.5MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with rand for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  6.54it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:44<00:00, 22.46s/it]\n",
            "Post-training time: 227.04 seconds\n",
            "GPU memory allocated: 374.89 MB, peak: 882.10 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.302585          10.47          50.00\n",
            "Final      10    2.302676   2.302586          10.00          50.00\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.100694  ...            0.356814  1.392548e+03      True\n",
            "1    layers.0.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.100423  ...            0.362516  2.936300e+04      True\n",
            "3    layers.1.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.100898  ...            0.364253  5.885236e+04      True\n",
            "5    layers.3.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.099765  ...            0.362089  1.174851e+05      True\n",
            "7    layers.4.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.099565  ...            0.363171  2.357931e+05      True\n",
            "9    layers.6.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.100325  ...            0.363779  4.708842e+05      True\n",
            "11   layers.7.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.099257  ...            0.363243  4.701573e+05      True\n",
            "13   layers.8.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.100311  ...            0.363700  9.424383e+05      True\n",
            "15  layers.10.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.100044  ...            0.363858  1.882542e+06      True\n",
            "17  layers.11.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.100143  ...            0.363222  1.882466e+06      True\n",
            "19  layers.12.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.100048  ...            0.363228  1.881990e+06      True\n",
            "21  layers.14.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.099625  ...            0.362642  1.880025e+06      True\n",
            "23  layers.15.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.100114  ...            0.363466  1.881731e+06      True\n",
            "25  layers.16.conv    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "26              fc  weight  0.103906  ...            0.365161  4.088806e+03      True\n",
            "27              fc    bias  1.000000  ...            0.000000  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475792/14719818 (0.1003)\n",
            "FLOP Sparsity: 31608901/313478154 (0.1008)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 1 --post-epoch 10 --expid exp1_vgg16_cifar10_rand\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKwdTjk7KubF",
        "outputId": "9d102114-4aa2-4a2a-cb45-3f69e381d445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 10 epochs.\n",
            "100% 10/10 [03:47<00:00, 22.71s/it]\n",
            "Pruning with mag for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  6.46it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:44<00:00, 22.49s/it]\n",
            "Post-training time: 227.30 seconds\n",
            "GPU memory allocated: 375.42 MB, peak: 883.94 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  10    0.634267   0.641342          78.42          98.14\n",
            "Post-Prune 0          NaN   2.183902          26.56          62.29\n",
            "Final      10    0.356206   0.506354          84.17          98.83\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.856481  ...            0.026178    373.472107      True\n",
            "1    layers.0.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "2    layers.1.conv  weight  0.452827  ...            0.001628   1937.291992      True\n",
            "3    layers.1.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "4    layers.3.conv  weight  0.456692  ...            0.001688   3920.283691      True\n",
            "5    layers.3.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "6    layers.4.conv  weight  0.343079  ...            0.001126   6223.495117      True\n",
            "7    layers.4.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "8    layers.6.conv  weight  0.341448  ...            0.001125  12415.386719      True\n",
            "9    layers.6.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "10   layers.7.conv  weight  0.242686  ...            0.000856  20393.894531      True\n",
            "11   layers.7.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "12   layers.8.conv  weight  0.226890  ...            0.000798  19658.455078      True\n",
            "13   layers.8.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "14  layers.10.conv  weight  0.223124  ...            0.000764  38876.351562      True\n",
            "15  layers.10.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "16  layers.11.conv  weight  0.092665  ...            0.000405  53604.074219      True\n",
            "17  layers.11.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "18  layers.12.conv  weight  0.065575  ...            0.000314  48681.199219      True\n",
            "19  layers.12.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "20  layers.14.conv  weight  0.052238  ...            0.000265  46248.800781      True\n",
            "21  layers.14.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "22  layers.15.conv  weight  0.045307  ...            0.000239  44924.226562      True\n",
            "23  layers.15.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "24  layers.16.conv  weight  0.051974  ...            0.000258  46095.039062      True\n",
            "25  layers.16.conv    bias  1.000000  ...            0.000000      0.000000     False\n",
            "26              fc  weight  0.421680  ...            0.001447    253.777786      True\n",
            "27              fc    bias  1.000000  ...            0.000000      0.000000     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475792/14719818 (0.1003)\n",
            "FLOP Sparsity: 76224585/313478154 (0.2432)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 1 --pre-epochs 10 --post-epoch 10 --expid exp1_vgg16_cifar10_mag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PltNJd4eLjpz",
        "outputId": "9a9e3741-6d96-4623-8ea6-6cd6283dc2ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with snip for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.73it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:47<00:00, 22.78s/it]\n",
            "Post-training time: 230.17 seconds\n",
            "GPU memory allocated: 437.42 MB, peak: 943.98 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.326953          10.00          50.00\n",
            "Final      10    0.653573   0.689672          76.62          98.16\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.874421  ...        6.375356e-12      0.003846      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "2    layers.1.conv  weight  0.477349  ...        3.769962e-13      0.014017      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "4    layers.3.conv  weight  0.378526  ...        2.926648e-13      0.022258      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "6    layers.4.conv  weight  0.248664  ...        1.293747e-13      0.026055      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "8    layers.6.conv  weight  0.198558  ...        8.620113e-14      0.040440      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "10   layers.7.conv  weight  0.136880  ...        4.426740e-14      0.054485      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "12   layers.8.conv  weight  0.151538  ...        4.516491e-14      0.058510      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "14  layers.10.conv  weight  0.132489  ...        3.122938e-14      0.100847      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "16  layers.11.conv  weight  0.079922  ...        1.596756e-14      0.130301      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "18  layers.12.conv  weight  0.081544  ...        1.532614e-14      0.132795      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "20  layers.14.conv  weight  0.098686  ...        2.105110e-14      0.149217      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "22  layers.15.conv  weight  0.080535  ...        2.291960e-14      0.124919      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "24  layers.16.conv  weight  0.082788  ...        2.587651e-14      0.129478      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "26              fc  weight  0.744336  ...        1.778394e-11      0.012832      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475793/14719818 (0.1003)\n",
            "FLOP Sparsity: 62081564/313478154 (0.1980)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_vgg16_cifar10_snip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMftCP-2Lr5C",
        "outputId": "cf18d255-f82a-4792-d1c0-1f21a0a53677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 'singleshot' with expid 'exp1_vgg16_cifar10_grasp' exists.  Overwrite (yes/no)? yes\n",
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with grasp for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:45<00:00, 22.60s/it]\n",
            "Post-training time: 228.38 seconds\n",
            "GPU memory allocated: 376.07 MB, peak: 917.83 MB\n",
            "Train results:\n",
            "                 train_loss     test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0           NaN  2.417717e+00          11.73          50.17\n",
            "Pre-Prune  0           NaN  2.417717e+00          11.73          50.17\n",
            "Post-Prune 0           NaN  7.399683e+09          10.00          49.99\n",
            "Final      10  1543.920081  2.960650e+03          11.77          50.46\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.532407  ...        6.390277e-08      0.259138      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "2    layers.1.conv  weight  0.369439  ...        3.512055e-09      0.916489      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "4    layers.3.conv  weight  0.301107  ...        1.441624e-09      1.159186      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "6    layers.4.conv  weight  0.218791  ...        4.629983e-10      1.148464      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "8    layers.6.conv  weight  0.185601  ...        1.810968e-10      1.457950      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "10   layers.7.conv  weight  0.142054  ...        4.627594e-11      1.493271      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "12   layers.8.conv  weight  0.148037  ...        2.935169e-11      1.308237      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "14  layers.10.conv  weight  0.127271  ...        1.158296e-11      1.826353      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "16  layers.11.conv  weight  0.082917  ...        3.467025e-12      2.085933      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "18  layers.12.conv  weight  0.088694  ...        2.856631e-12      2.117609      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "20  layers.14.conv  weight  0.087897  ...        3.055562e-12      2.059873      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "22  layers.15.conv  weight  0.083056  ...        3.541244e-12      1.973260      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "24  layers.16.conv  weight  0.091459  ...        4.562688e-12      2.227648      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "26              fc  weight  0.506641  ...        3.991572e-09      0.193356      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00      0.000000     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475792/14719818 (0.1003)\n",
            "FLOP Sparsity: 54919691/313478154 (0.1752)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_vgg16_cifar10_grasp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAsfa2_Iv_ty",
        "outputId": "f6a4da53-9cbd-4886-d7b7-d1198ff27fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.04it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:45<00:00, 22.52s/it]\n",
            "Post-training time: 227.65 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.302601          10.00          49.95\n",
            "Final      10    0.524392   0.568477          80.63          99.07\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.997106  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.964790  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.928589  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.859741  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.726661  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.484929  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.484745  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.162064  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.007960  ...        9.402646e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.007958  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.029585  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.029672  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.033553  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.994922  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475792/14719818 (0.1003)\n",
            "FLOP Sparsity: 143301021/313478154 (0.4571)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_vgg16_cifar10_synflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvykXE2-N97U"
      },
      "source": [
        "FC Model with MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijn28i_YMFFA",
        "outputId": "944fc282-1fd5-480c-f738-89507584a5a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mnist dataset.\n",
            "100% 9.91M/9.91M [00:00<00:00, 14.6MB/s]\n",
            "100% 28.9k/28.9k [00:00<00:00, 469kB/s]\n",
            "100% 1.65M/1.65M [00:00<00:00, 4.45MB/s]\n",
            "100% 4.54k/4.54k [00:00<00:00, 18.3MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating default-fc model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with rand for 1 epochs.\n",
            "100% 1/1 [00:00<00:00, 13.75it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [02:08<00:00, 12.82s/it]\n",
            "Post-training time: 129.94 seconds\n",
            "GPU memory allocated: 19.93 MB, peak: 22.23 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.306856          10.32          47.39\n",
            "Pre-Prune  0          NaN   2.306856          10.32          47.39\n",
            "Post-Prune 0          NaN   2.305038          10.32          49.26\n",
            "Final      10    0.177668   0.180216          94.49          99.80\n",
            "Prune results:\n",
            "    module   param  sparsity   size  ... score abs mean  score abs variance  score abs sum  prunable\n",
            "0       1  weight  0.100969  78400  ...       0.800812            0.365711   62783.628906      True\n",
            "1       1    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "2       3  weight  0.098400  10000  ...       0.792052            0.367775    7920.516602      True\n",
            "3       3    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "4       5  weight  0.099500  10000  ...       0.789619            0.352073    7896.190430      True\n",
            "5       5    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "6       7  weight  0.097400  10000  ...       0.791694            0.361521    7916.939453      True\n",
            "7       7    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "8       9  weight  0.096800  10000  ...       0.792565            0.354341    7925.648438      True\n",
            "9       9    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "10     11  weight  0.103000   1000  ...       0.826184            0.353799     826.184204      True\n",
            "11     11    bias  1.000000     10  ...       0.000000            0.000000       0.000000     False\n",
            "\n",
            "[12 rows x 13 columns]\n",
            "Parameter Sparsity: 12450/119910 (0.1038)\n",
            "FLOP Sparsity: 12450/119910 (0.1038)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class default --model fc --dataset mnist --experiment singleshot --pruner rand --compression 1 --post-epoch 10 --expid exp1_fc_mnist_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FByuMk_XNtP3",
        "outputId": "30ef75fc-34b8-46f6-d64b-4341b050bb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mnist dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating default-fc model.\n",
            "Pre-Train for 10 epochs.\n",
            "100% 10/10 [02:14<00:00, 13.46s/it]\n",
            "Pruning with mag for 1 epochs.\n",
            "100% 1/1 [00:00<00:00, 42.74it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [02:05<00:00, 12.53s/it]\n",
            "Post-training time: 127.12 seconds\n",
            "GPU memory allocated: 19.93 MB, peak: 22.23 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.306856          10.32          47.39\n",
            "Pre-Prune  10    0.038163   0.099144          97.37          99.92\n",
            "Post-Prune 0          NaN   1.800025          60.80          95.76\n",
            "Final      10    0.030020   0.088591          97.74          99.92\n",
            "Prune results:\n",
            "    module   param  sparsity   size  ... score abs mean  score abs variance  score abs sum  prunable\n",
            "0       1  weight  0.050906  78400  ...       0.036366            0.001142    2851.101562      True\n",
            "1       1    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "2       3  weight  0.224300  10000  ...       0.069534            0.002548     695.339355      True\n",
            "3       3    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "4       5  weight  0.210000  10000  ...       0.066849            0.002287     668.490967      True\n",
            "5       5    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "6       7  weight  0.178900  10000  ...       0.062703            0.001849     627.027466      True\n",
            "7       7    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "8       9  weight  0.156400  10000  ...       0.060283            0.001640     602.833984      True\n",
            "9       9    bias  1.000000    100  ...       0.000000            0.000000       0.000000     False\n",
            "10     11  weight  0.253000   1000  ...       0.070309            0.002113      70.308563      True\n",
            "11     11    bias  1.000000     10  ...       0.000000            0.000000       0.000000     False\n",
            "\n",
            "[12 rows x 13 columns]\n",
            "Parameter Sparsity: 12449/119910 (0.1038)\n",
            "FLOP Sparsity: 12449/119910 (0.1038)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class default --model fc --dataset mnist --experiment singleshot --pruner mag --compression 1 --pre-epochs 10 --post-epoch 10 --expid exp1_fc_mnist_mag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNmeMoCjNyjb",
        "outputId": "254f2c56-82a6-479b-834b-dff25a892935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mnist dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating default-fc model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with snip for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  5.63it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [02:05<00:00, 12.54s/it]\n",
            "Post-training time: 127.32 seconds\n",
            "GPU memory allocated: 20.41 MB, peak: 22.71 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.306856          10.32          47.39\n",
            "Pre-Prune  0          NaN   2.306856          10.32          47.39\n",
            "Post-Prune 0          NaN   2.306854          10.32          49.80\n",
            "Final      10    0.129195   0.143946          95.60          99.81\n",
            "Prune results:\n",
            "    module   param  sparsity   size  ... score abs mean  score abs variance  score abs sum  prunable\n",
            "0       1  weight  0.054056  78400  ...       0.000005        5.989313e-11       0.404448      True\n",
            "1       1    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "2       3  weight  0.218900  10000  ...       0.000013        4.284687e-10       0.125934      True\n",
            "3       3    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "4       5  weight  0.181800  10000  ...       0.000011        4.830764e-10       0.111812      True\n",
            "5       5    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "6       7  weight  0.151100  10000  ...       0.000010        6.846698e-10       0.103630      True\n",
            "7       7    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "8       9  weight  0.176600  10000  ...       0.000016        2.011727e-09       0.158670      True\n",
            "9       9    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "10     11  weight  0.418000   1000  ...       0.000096        5.414623e-08       0.095505      True\n",
            "11     11    bias  1.000000     10  ...       0.000000        0.000000e+00       0.000000     False\n",
            "\n",
            "[12 rows x 13 columns]\n",
            "Parameter Sparsity: 12449/119910 (0.1038)\n",
            "FLOP Sparsity: 12449/119910 (0.1038)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class default --model fc --dataset mnist --experiment singleshot --pruner snip --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_fc_mnist_snip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyGvYJweN1hi",
        "outputId": "932ace6d-c30d-4174-880a-6ea4d75817e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mnist dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating default-fc model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with grasp for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.83it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [02:03<00:00, 12.37s/it]\n",
            "Post-training time: 125.36 seconds\n",
            "GPU memory allocated: 19.93 MB, peak: 22.23 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.306856          10.32          47.39\n",
            "Pre-Prune  0          NaN   2.306856          10.32          47.39\n",
            "Post-Prune 0          NaN   2.387675          10.08          49.31\n",
            "Final      10    0.161216   0.178541          94.68          99.69\n",
            "Prune results:\n",
            "    module   param  sparsity   size  ... score abs mean  score abs variance  score abs sum  prunable\n",
            "0       1  weight  0.051645  78400  ...       0.000013        4.010847e-10       0.980858      True\n",
            "1       1    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "2       3  weight  0.216500  10000  ...       0.000045        7.668780e-09       0.450646      True\n",
            "3       3    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "4       5  weight  0.206200  10000  ...       0.000052        1.109022e-08       0.519234      True\n",
            "5       5    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "6       7  weight  0.176400  10000  ...       0.000061        2.182159e-08       0.607798      True\n",
            "7       7    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "8       9  weight  0.156500  10000  ...       0.000066        3.037866e-08       0.663623      True\n",
            "9       9    bias  1.000000    100  ...       0.000000        0.000000e+00       0.000000     False\n",
            "10     11  weight  0.335000   1000  ...       0.000315        3.629368e-07       0.315077      True\n",
            "11     11    bias  1.000000     10  ...       0.000000        0.000000e+00       0.000000     False\n",
            "\n",
            "[12 rows x 13 columns]\n",
            "Parameter Sparsity: 12450/119910 (0.1038)\n",
            "FLOP Sparsity: 12450/119910 (0.1038)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class default --model fc --dataset mnist --experiment singleshot --pruner grasp --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_fc_mnist_grasp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fTUNl1tN3ob",
        "outputId": "ee211b6e-7cbd-41aa-9d97-e609f339ace1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mnist dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating default-fc model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  3.78it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [02:04<00:00, 12.49s/it]\n",
            "Post-training time: 127.44 seconds\n",
            "GPU memory allocated: 19.93 MB, peak: 22.23 MB\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.306856          10.32          47.39\n",
            "Pre-Prune  0          NaN   2.306856          10.32          47.39\n",
            "Post-Prune 0          NaN   2.306644          10.32          49.80\n",
            "Final      10     2.30135   2.301037          11.35          52.14\n",
            "Prune results:\n",
            "    module   param  sparsity   size  ... score abs mean  score abs variance  score abs sum  prunable\n",
            "0       1  weight    0.0000  78400  ...       5.375413            9.872970   421432.37500      True\n",
            "1       1    bias    1.0000    100  ...       0.000000            0.000000        0.00000     False\n",
            "2       3  weight    0.2801  10000  ...      42.197376          606.436279   421973.75000      True\n",
            "3       3    bias    1.0000    100  ...       0.000000            0.000000        0.00000     False\n",
            "4       5  weight    0.2774  10000  ...      42.228401          605.871582   422284.00000      True\n",
            "5       5    bias    1.0000    100  ...       0.000000            0.000000        0.00000     False\n",
            "6       7  weight    0.2796  10000  ...      42.234432          616.338806   422344.31250      True\n",
            "7       7    bias    1.0000    100  ...       0.000000            0.000000        0.00000     False\n",
            "8       9  weight    0.2638  10000  ...      42.235733          690.546753   422357.31250      True\n",
            "9       9    bias    1.0000    100  ...       0.000000            0.000000        0.00000     False\n",
            "10     11  weight    0.9310   1000  ...     422.359283        62346.089844   422359.28125      True\n",
            "11     11    bias    1.0000     10  ...       0.000000            0.000000        0.00000     False\n",
            "\n",
            "[12 rows x 13 columns]\n",
            "Parameter Sparsity: 12449/119910 (0.1038)\n",
            "FLOP Sparsity: 12449/119910 (0.1038)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class default --model fc --dataset mnist --experiment singleshot --pruner synflow --compression 1 --pre-epochs 0 --post-epoch 10 --expid exp1_fc_mnist_synflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw_Np0UCc_lg"
      },
      "source": [
        "### Tuning compression ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSphNFrqc_J5",
        "outputId": "20eeabf5-8756-4e45-988d-21d7a47de239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.54it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:49<00:00, 22.94s/it]\n",
            "Post-training time: 232.82 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.414332          11.66          50.38\n",
            "Final      10    0.595632   0.678205          76.59          98.27\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  1.000000  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.998264  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.996460  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.993198  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.986152  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.972612  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.972772  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.944177  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.888635  ...        9.402646e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.888531  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.865655  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.866078  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.856663  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.999609  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 13119512/14719818 (0.8913)\n",
            "FLOP Sparsity: 297416253/313478154 (0.9488)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 0.05 --expid exp1_vgg16_cifar10_synflow_0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAZsi4U_pSuu",
        "outputId": "1653c3f9-6857-465e-e90d-42493bb9a8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cifar10 dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  1.73it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [03:48<00:00, 22.81s/it]\n",
            "Post-training time: 230.62 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.403514          11.46          49.92\n",
            "Final      10    0.599284   0.650703          78.67          98.37\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.999421  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.996582  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.993096  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.986925  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.974199  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.947367  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.947562  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.892713  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.788353  ...        9.402646e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.787956  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.746524  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.746590  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.731970  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.999609  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 11693237/14719818 (0.7944)\n",
            "FLOP Sparsity: 282939167/313478154 (0.9026)\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 0.1 --expid exp1_vgg16_cifar10_synflow_0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvXJGZmApY1C",
        "outputId": "652c8640-f078-4f99-d240-d19021a03fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 'singleshot' with expid 'exp1_vgg16_cifar10_synflow_0.2' exists.  Overwrite (yes/no)? yes\n",
            "Loading cifar10 dataset.\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  1.57it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [04:07<00:00, 24.76s/it]\n",
            "Post-training time: 250.19 seconds\n",
            "Measuring inference time...\n",
            "Inference time: 2.9135 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.396131          10.05          51.06\n",
            "Final      10    0.568812   0.730841          75.85          97.80\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.998843  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.993490  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.987115  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.974752  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.950578  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.900650  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.900650  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.799322  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.611696  ...        9.402645e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.611218  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.549993  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.550156  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.533391  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.999219  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 9289138/14719818 (0.6311)\n",
            "FLOP Sparsity: 257583382/313478154 (0.8217)\n",
            "Inference Time: 2.9135 seconds\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 0.2 --expid exp1_vgg16_cifar10_synflow_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Cd-beypawf",
        "outputId": "6e3c18df-85f0-4f77-ac06-0c41fa2727c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 'singleshot' with expid 'exp1_vgg16_cifar10_synflow_0.5' exists.  Overwrite (yes/no)? yes\n",
            "Loading cifar10 dataset.\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  1.70it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [04:10<00:00, 25.05s/it]\n",
            "Post-training time: 253.43 seconds\n",
            "Measuring inference time...\n",
            "Inference time: 2.5342 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.329115           9.99          51.15\n",
            "Final      10    0.499955   0.589575          79.96          98.57\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.997685  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.983805  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.969618  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.940477  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.881911  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.766754  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.766447  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.546590  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.232446  ...        9.402645e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.232694  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.211462  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.211558  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.210058  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.997656  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 4657710/14719818 (0.3164)\n",
            "FLOP Sparsity: 201358519/313478154 (0.6423)\n",
            "Inference Time: 2.5342 seconds\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 0.5 --expid exp1_vgg16_cifar10_synflow_0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipmqWeMmpdo2",
        "outputId": "d20d171e-f316-4250-a123-54351d157f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cifar10 dataset.\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.41it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [04:10<00:00, 25.05s/it]\n",
            "Post-training time: 253.10 seconds\n",
            "Measuring inference time...\n",
            "Inference time: 2.9387 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.302601          10.00          49.95\n",
            "Final      10    0.509055   0.561710          80.93          98.96\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.997106  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.964790  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.928589  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.859741  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.726661  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.484929  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.484745  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.162064  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.007960  ...        9.402645e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.007958  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.029585  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.029672  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.033553  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.994922  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 1475792/14719818 (0.1003)\n",
            "FLOP Sparsity: 143301021/313478154 (0.4571)\n",
            "Inference Time: 2.9387 seconds\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 1 --expid exp1_vgg16_cifar10_synflow_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMsuxxApfRi",
        "outputId": "b12253a7-01b2-4651-a2e7-9a5f4d7d3a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cifar10 dataset.\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with synflow for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  2.65it/s]\n",
            "Post-Training for 10 epochs.\n",
            "100% 10/10 [04:08<00:00, 24.83s/it]\n",
            "Post-training time: 250.95 seconds\n",
            "Measuring inference time...\n",
            "Inference time: 2.9473 seconds\n",
            "GPU memory allocated: 375.68 MB, peak: 882.10 MB\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
            "Train results:\n",
            "                train_loss  test_loss  top1_accuracy  top5_accuracy\n",
            "Init.      0          NaN   2.417717          11.73          50.17\n",
            "Pre-Prune  0          NaN   2.417717          11.73          50.17\n",
            "Post-Prune 0          NaN   2.302585          10.00          50.00\n",
            "Final      10    2.302666   2.302590          10.00          50.00\n",
            "Prune results:\n",
            "             module   param  sparsity  ...  score abs variance score abs sum  prunable\n",
            "0    layers.0.conv  weight  0.988426  ...                 inf  2.945027e+22      True\n",
            "1    layers.0.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "2    layers.1.conv  weight  0.806396  ...                 inf  2.945027e+22      True\n",
            "3    layers.1.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "4    layers.3.conv  weight  0.626017  ...                 inf  2.945027e+22      True\n",
            "5    layers.3.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "6    layers.4.conv  weight  0.332425  ...                 inf  2.945027e+22      True\n",
            "7    layers.4.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "8    layers.6.conv  weight  0.052199  ...                 inf  2.945027e+22      True\n",
            "9    layers.6.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "10   layers.7.conv  weight  0.000154  ...                 inf  2.945027e+22      True\n",
            "11   layers.7.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "12   layers.8.conv  weight  0.000112  ...                 inf  2.945027e+22      True\n",
            "13   layers.8.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "14  layers.10.conv  weight  0.000000  ...                 inf  2.945027e+22      True\n",
            "15  layers.10.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "16  layers.11.conv  weight  0.000000  ...        9.402645e+31  2.945026e+22      True\n",
            "17  layers.11.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "18  layers.12.conv  weight  0.000000  ...        9.415211e+31  2.945027e+22      True\n",
            "19  layers.12.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "20  layers.14.conv  weight  0.000000  ...                 inf  2.945027e+22      True\n",
            "21  layers.14.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "22  layers.15.conv  weight  0.000000  ...                 inf  2.945026e+22      True\n",
            "23  layers.15.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "24  layers.16.conv  weight  0.000000  ...                 inf  2.945028e+22      True\n",
            "25  layers.16.conv    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "26              fc  weight  0.975977  ...                 inf  2.945027e+22      True\n",
            "27              fc    bias  1.000000  ...        0.000000e+00  0.000000e+00     False\n",
            "\n",
            "[28 rows x 13 columns]\n",
            "Parameter Sparsity: 151390/14719818 (0.0103)\n",
            "FLOP Sparsity: 57830479/313478154 (0.1845)\n",
            "Inference Time: 2.9473 seconds\n",
            "Saving results.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner synflow --compression 2 --expid exp1_vgg16_cifar10_synflow_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o9rtXkGfqEj",
        "outputId": "e3fe1b31-a507-4a23-fb88-fb87c8e0fcf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cifar10 dataset.\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creating lottery-vgg16 model.\n",
            "Pre-Train for 0 epochs.\n",
            "0it [00:00, ?it/s]\n",
            "Pruning with rand for 1 epochs.\n",
            "100% 1/1 [00:00<00:00,  5.80it/s]\n",
            "Post-Training for 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 0.05 --expid exp2_vgg16_cifar10_rand_0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWd3RD5Ap-bS"
      },
      "outputs": [],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 0.1 --expid exp2_vgg16_cifar10_rand_0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm6S4i03qAOH"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 0.2 --expid exp2_vgg16_cifar10_rand_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ase-qFsvqCIh"
      },
      "outputs": [],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 0.5 --expid exp2_vgg16_cifar10_rand_0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of1F3f_iqD4P"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 1 --expid exp2_vgg16_cifar10_rand_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbx7VS5GqF9E"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner rand --compression 2 --expid exp2_vgg16_cifar10_rand_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-uHDLDMgRIy"
      },
      "outputs": [],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 0.05 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fimcy-mLqIbq"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 0.1 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s_r1XhMqJ-V"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 0.2 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc7BGc9wqLxd"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 0.5 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IucKyDcqNJM"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 1 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yILCBw4gqPEY"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner mag --compression 2 --pre-epochs 10 --post-epoch 10 --expid exp3_vgg16_cifar10_mag_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH-4YEZZgvbS"
      },
      "outputs": [],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 0.1 --expid exp4_vgg16_cifar10_snip_0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwui6ptpqRrU"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 0.2 --expid exp4_vgg16_cifar10_snip_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bm99MD1qTZ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 0.5 --expid exp4_vgg16_cifar10_snip_0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEwWjroGqU02"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 1 --expid exp4_vgg16_cifar10_snip_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf-tZVKOqWId"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner snip --compression 2 --expid exp4_vgg16_cifar10_snip_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MbSwwfKg3lm"
      },
      "outputs": [],
      "source": [
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 0.1 --expid exp5_vgg16_cifar10_grasp_0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmPCmRtNqbpF"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 0.2 --expid exp5_vgg16_cifar10_grasp_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAlNTPOoqdh5"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 0.5 --expid exp5_vgg16_cifar10_grasp_0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyvLCtXGqfJW"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 1 --expid exp5_vgg16_cifar10_grasp_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYmKHG_cqgoE"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python COS568-Pruning-SP25/main.py --model-class lottery --model vgg16 --dataset cifar10 --experiment singleshot --pruner grasp --compression 2 --expid exp5_vgg16_cifar10_grasp_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT5Hq-LyxvH5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2wzQOmuxzbr"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Source folder (inside Colab)\n",
        "source_folder = \"/content/Results\"\n",
        "\n",
        "# Destination folder (inside Google Drive)\n",
        "destination_folder = \"/content/drive/My Drive/result\"\n",
        "\n",
        "# Copy the entire folder\n",
        "shutil.copytree(source_folder, destination_folder, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Folder saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXBh4qupyELq"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Post-Processing for SynFlow (compression=0.5)\n",
        "# --------------------------\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from models.lottery import Model  # Adjust based on your model class\n",
        "\n",
        "# Load Results\n",
        "expid = \"exp1_vgg16_cifar10_synflow_0.5\"\n",
        "prune_result = pd.read_pickle(f\"COS568-Pruning-SP25/results/{expid}/compression.pkl\")\n",
        "\n",
        "# Extract Layer-wise Sparsity (Weights Only)\n",
        "print(f\"\\\\n--- SynFlow Layer-wise Sparsity (compression=0.5) ---\")\n",
        "for _, row in prune_result[prune_result['param'] == 'weight'].iterrows():\n",
        "    print(f\"{row['module']}: {row['sparsity'] * 100:.2f}%\")\n",
        "\n",
        "# Load Model and Plot Histograms\n",
        "model = Model('vgg16', 'lottery', 'cifar10').cuda()\n",
        "model.load_state_dict(torch.load(f\"COS568-Pruning-SP25/results/{expid}/model.pt\"))\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "for i, (name, param) in enumerate(model.named_parameters()):\n",
        "    if 'weight' in name:\n",
        "        weights = param.detach().cpu().numpy().flatten()\n",
        "        plt.subplot(6, 3, i+1)\n",
        "        plt.hist(weights, bins=100, alpha=0.7)\n",
        "        plt.title(f\"{name} (Sparsity: {np.mean(weights == 0) * 100:.2f}%)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"histograms_synflow_0.5.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsFZ2uAogTb9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}